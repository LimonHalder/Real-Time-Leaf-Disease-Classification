{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab791169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display,clear_output\n",
    "from warnings import filterwarnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite','Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52fda4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/archive/PlantVillage/Pepper__bell___Bacterial_spot\n",
      "dataset/archive/PlantVillage/Pepper__bell___healthy\n",
      "dataset/archive/PlantVillage/Potato___Early_blight\n",
      "dataset/archive/PlantVillage/Potato___Late_blight\n",
      "dataset/archive/PlantVillage/Potato___healthy\n",
      "dataset/archive/PlantVillage/Tomato_Bacterial_spot\n",
      "dataset/archive/PlantVillage/Tomato_Early_blight\n",
      "dataset/archive/PlantVillage/Tomato_Late_blight\n",
      "dataset/archive/PlantVillage/Tomato_Leaf_Mold\n",
      "dataset/archive/PlantVillage/Tomato_Septoria_leaf_spot\n",
      "dataset/archive/PlantVillage/Tomato_Spider_mites_Two_spotted_spider_mite\n",
      "dataset/archive/PlantVillage/Tomato__Target_Spot\n",
      "dataset/archive/PlantVillage/Tomato__Tomato_mosaic_virus\n",
      "dataset/archive/PlantVillage/Tomato_healthy\n"
     ]
    }
   ],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "\n",
    "for i in labels:\n",
    "    \n",
    "    folderpath=os.path.join('dataset/archive/PlantVillage/',i)\n",
    "    print(folderpath)\n",
    "    for j in os.listdir(folderpath):\n",
    "        img=cv2.imread(os.path.join(folderpath,j))\n",
    "        img=cv2.resize(img,(244,244))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "772b0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d1c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d44795",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.5,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "561ad449",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new=[]\n",
    "\n",
    "\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train=y_train_new\n",
    "y_train=tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_test_new=[]\n",
    "\n",
    "for i in labels:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test=y_test_new\n",
    "y_test=tf.keras.utils.to_categorical(y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "083c42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(input_shape = (244, 244, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7083df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4fc2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = base_model.output\n",
    "\n",
    "model1 = tf.keras.layers.Dense(512,activation='relu')(model1)\n",
    "model1 = tf.keras.layers.GlobalAveragePooling2D()(model1)\n",
    "model1 = tf.keras.layers.Dropout(rate=0.5)(model1)\n",
    "model1 = tf.keras.layers.Dense(14,activation='softmax')(model1)\n",
    "model1 = tf.keras.models.Model(inputs=base_model.input, outputs = model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "980a3c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 244, 244, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 244, 244, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 244, 244, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 122, 122, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 122, 122, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 122, 122, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 61, 61, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 61, 61, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 30, 30, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 30, 30, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7, 7, 512)         262656    \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 14)                7182      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,984,526\n",
      "Trainable params: 269,838\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69750a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard1 = TensorBoard(log_dir = 'logs')\n",
    "checkpoint1 = ModelCheckpoint(\"vgg16\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr1 = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.0001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb48727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"Adam\",loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afead11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 5.6425 - accuracy: 0.2474 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.67429, saving model to vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 535s 22s/step - loss: 5.6425 - accuracy: 0.2474 - val_loss: 0.9904 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.6850 - accuracy: 0.5593 \n",
      "Epoch 2: val_accuracy improved from 0.67429 to 0.80000, saving model to vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 519s 21s/step - loss: 1.6850 - accuracy: 0.5593 - val_loss: 0.6709 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.9661 - accuracy: 0.6939 \n",
      "Epoch 3: val_accuracy improved from 0.80000 to 0.83429, saving model to vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 492s 20s/step - loss: 0.9661 - accuracy: 0.6939 - val_loss: 0.5728 - val_accuracy: 0.8343 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.7330 - accuracy: 0.7589 \n",
      "Epoch 4: val_accuracy did not improve from 0.83429\n",
      "25/25 [==============================] - 397s 16s/step - loss: 0.7330 - accuracy: 0.7589 - val_loss: 0.5709 - val_accuracy: 0.8229 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.7985 \n",
      "Epoch 5: val_accuracy did not improve from 0.83429\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "25/25 [==============================] - 927s 38s/step - loss: 0.5924 - accuracy: 0.7985 - val_loss: 0.4852 - val_accuracy: 0.8343 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.8520 \n",
      "Epoch 6: val_accuracy improved from 0.83429 to 0.85143, saving model to vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 410s 16s/step - loss: 0.4541 - accuracy: 0.8520 - val_loss: 0.4534 - val_accuracy: 0.8514 - lr: 4.0000e-04\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.8469 \n",
      "Epoch 7: val_accuracy did not improve from 0.85143\n",
      "25/25 [==============================] - 1182s 48s/step - loss: 0.4649 - accuracy: 0.8469 - val_loss: 0.4501 - val_accuracy: 0.8400 - lr: 4.0000e-04\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8756 \n",
      "Epoch 8: val_accuracy did not improve from 0.85143\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "25/25 [==============================] - 423s 17s/step - loss: 0.4077 - accuracy: 0.8756 - val_loss: 0.4523 - val_accuracy: 0.8457 - lr: 4.0000e-04\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8699 \n",
      "Epoch 9: val_accuracy did not improve from 0.85143\n",
      "25/25 [==============================] - 530s 21s/step - loss: 0.3944 - accuracy: 0.8699 - val_loss: 0.4398 - val_accuracy: 0.8514 - lr: 1.6000e-04\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.8814 \n",
      "Epoch 10: val_accuracy did not improve from 0.85143\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "25/25 [==============================] - 559s 22s/step - loss: 0.3710 - accuracy: 0.8814 - val_loss: 0.4344 - val_accuracy: 0.8400 - lr: 1.6000e-04\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train,y_train,validation_split=0.1, epochs =10, verbose=1, batch_size=64,\n",
    "                      callbacks=[tensorboard1,checkpoint1,reduce_lr1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca98acba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dataset/archive/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dataset/archive/assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('dataset/archive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5137693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "736feebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('dataset/archive/') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35336021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657a5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e30e33de",
   "metadata": {},
   "source": [
    "# Mobilnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f3ee244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "image_size = 244\n",
    "IMG_SHAPE = (image_size, image_size, 3)\n",
    "\n",
    "#Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False,\n",
    "                                              weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e85df316",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bab8d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e012c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                          base_model,\n",
    "                          keras.layers.GlobalAveragePooling2D(),\n",
    "                          keras.layers.Dense(14, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aeec3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff4472",
   "metadata": {},
   "outputs": [],
   "source": [
    " # previous one\n",
    "epochs = 100\n",
    "steps_per_epoch = 70\n",
    "validation_steps = 70\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              workers=4,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd81d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard1 = TensorBoard(log_dir = 'logs')\n",
    "checkpoint1 = ModelCheckpoint(\"vgg16\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr1 = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.0001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4800a699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8818\n",
      "Epoch 1: val_accuracy did not improve from 0.80275\n",
      "246/246 [==============================] - 217s 880ms/step - loss: 0.4135 - accuracy: 0.8818 - val_loss: 0.6096 - val_accuracy: 0.8005 - lr: 6.5536e-07\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train,y_train,validation_split=0.1, epochs =1, verbose=1, batch_size=32,\n",
    "                      callbacks=[tensorboard1,checkpoint1,reduce_lr1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a2c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img=cv2.imread('dataset/potato late blight.JPG')\n",
    "img=cv2.resize(img,(244,244))\n",
    "image=np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c88ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7deba2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 219s 802ms/step\n"
     ]
    }
   ],
   "source": [
    "u=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c366176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(u[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca9e700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dataset/archive/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dataset/archive/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('dataset/archive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aed90282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('vgg16/') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de45683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history1.history['accuracy']\n",
    "val_acc = history1.history['val_accuracy']\n",
    "\n",
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c5e1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8461e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 8, 8, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14)                17934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,275,918\n",
      "Trainable params: 17,934\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "savedModel=load_model('vgg16/')\n",
    "\n",
    "savedModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d320a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "u=savedModel(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905ebf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f3513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad527614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56635f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723dfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bd046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
